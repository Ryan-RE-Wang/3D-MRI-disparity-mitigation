{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, auc\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from scipy.ndimage import zoom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torchsummary import summary\n",
    "from transformation_3d import *\n",
    "from resnet3d import *\n",
    "from Custom_losses_3d import *\n",
    "\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (96, 96, 96)\n",
    "\n",
    "class ADNI_3D_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv, path, transform, task):\n",
    "\n",
    "        self.csv = csv\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.task = task\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.csv)\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        file_path = self.path + self.csv['Filename'].values[idx]\n",
    "        image = self.load_img(file_path)\n",
    "                \n",
    "        if self.transform > -2:\n",
    "            if (self.transform == -1):\n",
    "                rand = np.random.randint(0, 4, 1)\n",
    "            else:\n",
    "                rand = self.transform\n",
    "                \n",
    "            image = self.transformation(image, rand)\n",
    "\n",
    "        image = zoom(image, (96/image.shape[0], 96/image.shape[1], 96/image.shape[2]))\n",
    "        image = self.normalize(image)\n",
    "        \n",
    "        if (self.task == 'disease'):\n",
    "\n",
    "                    \n",
    "            if (self.csv['Group'].values[idx] == 'CN'):\n",
    "                label = 0\n",
    "            elif (self.csv['Group'].values[idx] == 'AD'):\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 1\n",
    "        elif (self.task == 'race'):\n",
    "            \n",
    "            if (self.csv['Race'].values[idx] == 0):\n",
    "                label = 0\n",
    "            elif (self.csv['Race'].values[idx] != 0):\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 1\n",
    "                \n",
    "        elif (self.task == 'age'):\n",
    "            \n",
    "            if (self.csv['Age'].values[idx] <= 75):\n",
    "                label = 0\n",
    "            elif (self.csv['Age'].values[idx] > 75):\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 1\n",
    "                \n",
    "        elif (self.task == 'sex'):\n",
    "            \n",
    "            if (self.csv['Sex'].values[idx] == 'F'):\n",
    "                label = 0\n",
    "            elif (self.csv['Sex'].values[idx] == 'M'):\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 1\n",
    "                \n",
    "        else:\n",
    "            print('Wrong task!')\n",
    "            \n",
    "            return \n",
    "        \n",
    "        demo = torch.tensor([0 if self.csv['Sex'].values[idx] == 'F' else 1,\n",
    "                             0 if self.csv['Age'].values[idx] <= 75 else 1])\n",
    "\n",
    "        image = torch.unsqueeze(torch.from_numpy(image), 0)\n",
    "        label = torch.tensor(label)\n",
    "                       \n",
    "        return image, label, demo\n",
    "    \n",
    "    def load_img(self, file_path):\n",
    "        data = nib.load(file_path)\n",
    "        data = np.array(data.dataobj)\n",
    "        return data\n",
    "    \n",
    "    def normalize(self, arr):\n",
    "        arr_min = np.min(arr)\n",
    "        arr_max = np.max(arr)\n",
    "        return (arr - arr_min) / (arr_max - arr_min)\n",
    "    \n",
    "    def transformation(self, img, rand):\n",
    "    \n",
    "        img_np = np.copy(img)\n",
    "\n",
    "        if (rand == 0):\n",
    "            img_np = shear(img_np, 6)\n",
    "        elif (rand == 1):\n",
    "            img_np = scale(img_np, 0.8)\n",
    "        elif (rand == 2):\n",
    "            img_np = fish(img_np, 0.4)\n",
    "        else:\n",
    "            img_np = rotation(img_np, 10)\n",
    "            \n",
    "            \n",
    "        return img_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(path, loss, auc, name):\n",
    "    f = open(path, 'a')\n",
    "    print('[%s] test_loss: %.3f // test_auc: %.3f ' % (name, loss, auc), file=f)                                                                          \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, df, data_path, model_path, epochs, transform, task, algo):\n",
    "    \n",
    "    num_worker = 16\n",
    "    Val_Data_set = ADNI_3D_Dataset(csv = df.loc[df['Split']=='val'], path = data_path, transform = transform, task = task)\n",
    "    Train_Data_set = ADNI_3D_Dataset(csv = df.loc[df['Split']=='train'], path = data_path, transform = transform, task = task)\n",
    "\n",
    "    val_dataloader = DataLoader(Val_Data_set, batch_size = batch_size, shuffle = True, num_workers = num_worker, pin_memory=True)\n",
    "    train_dataloader = DataLoader(Train_Data_set, batch_size = batch_size, shuffle = True, num_workers = num_worker, pin_memory=True)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    best_val_loss = float(\"Inf\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        if (algo == 'FairALM'):\n",
    "            lag_mult_r = torch.zeros(len(group_type['race']) * len(surrogate_fns))\n",
    "            lag_mult_g = torch.zeros(len(group_type['gender']) * len(surrogate_fns))\n",
    "            lag_mult_a = torch.zeros(len(group_type['age']) * len(surrogate_fns))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        model.train()\n",
    "        training_loss = 0.0 \n",
    "        train_accuracy = 0.0\n",
    "        loop = tqdm(enumerate(train_dataloader), total =len(train_dataloader))\n",
    "        for step, data in loop:     \n",
    "            inputs, labels, demo = data\n",
    "            inputs, labels, demo = inputs.to(device), labels.to(device), demo.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if (algo != 'Adv'):\n",
    "                outputs = torch.reshape(model(inputs), (len(labels),))\n",
    "            else:\n",
    "                all_outputs = model(inputs)\n",
    "                outputs_gender = torch.reshape(all_outputs[0], (len(labels), ))\n",
    "                outputs_age = torch.reshape(all_outputs[1], (len(labels), ))\n",
    "                outputs_disease = torch.reshape(all_outputs[2], (len(labels), ))\n",
    "                \n",
    "            if (algo == 'ERM'):\n",
    "                loss_value = ERM_Loss(labels.float(), outputs)\n",
    "            elif (algo == 'Adv'):\n",
    "                loss_value_gender = reciprocal_BCE_loss(demo[:, 0].float(), outputs_gender)\n",
    "                loss_value_age = reciprocal_BCE_loss(demo[:, 1].float(), outputs_age)\n",
    "                loss_value_disease = ERM_Loss(labels.float(), outputs_disease)\n",
    "                loss_value = loss_value_gender + loss_value_age + loss_value_disease\n",
    "            elif (algo == 'DistMatch'):\n",
    "                loss_value, penalty_g = DistMatch_Loss(labels.float(), outputs, demo[:, 0].float(), mode, 'gender')\n",
    "                loss_value, penalty_a = DistMatch_Loss(labels.float(), outputs, demo[:, 1].float(), mode, 'age')\n",
    "                loss_value = (loss_value + penalty_g + penalty_a)\n",
    "            elif (algo == 'FairALM'):\n",
    "                loss_value, penalty_g, lag_mult_g = fairALM_loss(labels.float(), outputs, demo[:, 0].float(), lag_mult_g, 'gender', False)\n",
    "                loss_value, penalty_a, lag_mult_a = fairALM_loss(labels.float(), outputs, demo[:, 1].float(), lag_mult_a, 'age', False)\n",
    "                loss_value += (loss_value + penalty_g + penalty_a)\n",
    "            else:\n",
    "                print('Wrong algo!')\n",
    "                break\n",
    "                \n",
    "            weight = torch.ones_like(loss_value)\n",
    "            weight[labels==1.] = weights[1]\n",
    "            loss = (loss_value * weight).mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss += loss.item()\n",
    "    \n",
    "            loop.set_description(f'Training epoch [{epoch}/80]')\n",
    "            loop.set_postfix(loss = training_loss/(step+1))\n",
    "\n",
    "        scheduler.step()\n",
    "        train_losses.append(training_loss/len(train_dataloader))\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        valid_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            loop = tqdm(enumerate(val_dataloader), total =len(val_dataloader))\n",
    "            for step, data in loop:\n",
    "                inputs, labels, demo = data\n",
    "                inputs, labels, demo = inputs.to(device), labels.to(device), demo.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if (algo != 'Adv'):\n",
    "                    outputs = torch.reshape(model(inputs), (len(labels),))\n",
    "                else:\n",
    "                    all_outputs = model(inputs)\n",
    "                    outputs_gender = torch.reshape(all_outputs[0], (len(labels), ))\n",
    "                    outputs_age = torch.reshape(all_outputs[1], (len(labels), ))\n",
    "                    outputs_disease = torch.reshape(all_outputs[2], (len(labels), ))\n",
    "\n",
    "                if (algo == 'ERM'):\n",
    "                    loss_value = ERM_Loss(labels.float(), outputs)\n",
    "                elif (algo == 'Adv'):\n",
    "                    loss_value_gender = reciprocal_BCE_loss(demo[:, 0].float(), outputs_gender)\n",
    "                    loss_value_age = reciprocal_BCE_loss(demo[:, 1].float(), outputs_age)\n",
    "                    loss_value_disease = ERM_Loss(labels.float(), outputs_disease)\n",
    "                    loss_value = loss_value_gender + loss_value_age + loss_value_disease\n",
    "                elif (algo == 'DistMatch'):\n",
    "                    loss_value, penalty_g = DistMatch_Loss(labels.float(), outputs, demo[:, 0].float(), mode, 'gender')\n",
    "                    loss_value, penalty_a = DistMatch_Loss(labels.float(), outputs, demo[:, 1].float(), mode, 'age')\n",
    "                    loss_value = (loss_value + penalty_g + penalty_a)\n",
    "                elif (algo == 'FairALM'):\n",
    "                    loss_value, penalty_g, lag_mult_g = fairALM_loss(labels.float(), outputs, demo[:, 0].float(), lag_mult_g, 'gender', False)\n",
    "                    loss_value, penalty_a, lag_mult_a = fairALM_loss(labels.float(), outputs, demo[:, 1].float(), lag_mult_a, 'age', False)\n",
    "                    loss_value += (loss_value + penalty_g + penalty_a)\n",
    "                else:\n",
    "                    print('Wrong algo!')\n",
    "                    break\n",
    "\n",
    "                weight = torch.ones_like(loss_value)\n",
    "                weight[labels==1.] = weights[1]\n",
    "                loss = (loss_value * weight).mean()\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                loop.set_description(f'Validataion epoch [{epoch}/80]')\n",
    "                loop.set_postfix(loss = valid_loss/(step+1))\n",
    "\n",
    "        val_losses.append(valid_loss / len(val_dataloader))\n",
    "        if(valid_loss/len(val_dataloader) < best_val_loss):\n",
    "            count = 0\n",
    "            best_val_loss = valid_loss/len(val_dataloader)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"=========save model=========\")\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        if (count > 10):\n",
    "            print(\"=========Early stopping=========\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fper, tper):\n",
    "    plt.plot(fper, tper, color='red', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def eval_step(model, df, data_csv, model_path, val, transform, task):\n",
    "    \n",
    "    num_worker = 1\n",
    "    if (val):\n",
    "        split = 'val'\n",
    "        Data_set = ADNI_3D_Dataset(csv = df.loc[df['Split']==split], path = data_path, transform = transform, task = task)\n",
    "        dataloader = DataLoader(Data_set, batch_size = batch_size, shuffle = False, num_workers = num_worker, pin_memory=True)\n",
    "\n",
    "    else:\n",
    "        split = 'test'\n",
    "        Data_set = ADNI_3D_Dataset(csv = df.loc[df['Split']==split], path = data_path, transform = -2, task = task)\n",
    "        dataloader = DataLoader(Data_set, batch_size = batch_size, shuffle = False, num_workers = num_worker, pin_memory=True)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    test_loss = 0.0\n",
    "    target=[]\n",
    "    prob=[]\n",
    "    \n",
    "    if (algo == 'FairALM'):\n",
    "        lag_mult_r = torch.zeros(len(group_type['race']) * len(surrogate_fns))\n",
    "        lag_mult_g = torch.zeros(len(group_type['gender']) * len(surrogate_fns))\n",
    "        lag_mult_a = torch.zeros(len(group_type['age']) * len(surrogate_fns))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(enumerate(dataloader), total =len(dataloader))\n",
    "        for step, data in loop:\n",
    "            inputs, labels, demo = data\n",
    "            inputs, labels, demo = inputs.to(device), labels.to(device), demo.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if (algo != 'Adv'):\n",
    "                outputs = torch.reshape(model(inputs), (len(labels),))\n",
    "            else:\n",
    "                all_outputs = model(inputs)\n",
    "                outputs_gender = torch.reshape(all_outputs[0], (len(labels), ))\n",
    "                outputs_age = torch.reshape(all_outputs[1], (len(labels), ))\n",
    "                outputs_disease = torch.reshape(all_outputs[2], (len(labels), ))\n",
    "\n",
    "            if (algo == 'ERM'):\n",
    "                loss_value = ERM_Loss(labels.float(), outputs)\n",
    "            elif (algo == 'Adv'):\n",
    "                loss_value_gender = reciprocal_BCE_loss(demo[:, 0].float(), outputs_gender)\n",
    "                loss_value_age = reciprocal_BCE_loss(demo[:, 1].float(), outputs_age)\n",
    "                loss_value_disease = ERM_Loss(labels.float(), outputs_disease)\n",
    "                loss_value = loss_value_gender + loss_value_age + loss_value_disease\n",
    "            elif (algo == 'DistMatch'):\n",
    "                loss_value, penalty_g = DistMatch_Loss(labels.float(), outputs, demo[:, 0].float(), mode, 'gender')\n",
    "                loss_value, penalty_a = DistMatch_Loss(labels.float(), outputs, demo[:, 1].float(), mode, 'age')\n",
    "                loss_value = (loss_value + penalty_g + penalty_a)\n",
    "            elif (algo == 'FairALM'):\n",
    "                loss_value, penalty_g, lag_mult_g = fairALM_loss(labels.float(), outputs, demo[:, 0].float(), lag_mult_g, 'gender', False)\n",
    "                loss_value, penalty_a, lag_mult_a = fairALM_loss(labels.float(), outputs, demo[:, 1].float(), lag_mult_a, 'age', False)\n",
    "                loss_value += (loss_value + penalty_g + penalty_a)\n",
    "            else:\n",
    "                print('Wrong algo!')\n",
    "                break\n",
    "\n",
    "            weight = torch.ones_like(loss_value)\n",
    "            weight[labels==1.] = weights[1]\n",
    "            loss = (loss_value * weight).mean()\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            target.extend(np.array(labels.cpu()))\n",
    "            \n",
    "            if (algo != 'Adv'):\n",
    "                prob.extend(outputs.detach().cpu().numpy())\n",
    "            else:\n",
    "                prob.extend(outputs_disease.detach().cpu().numpy())\n",
    "\n",
    "            loop.set_description(f'Test epoch')\n",
    "            loop.set_postfix(step=(step+1), loss = test_loss/(step+1))\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(target, prob)\n",
    "    auc_curve = auc(fpr, tpr)\n",
    "    print(\"AUC: \", auc_curve)\n",
    "    \n",
    "    if (val):\n",
    "        best_thresh = cal_best_thresh(np.array(target), np.array(prob))\n",
    "\n",
    "        np.savetxt('thresh/{i}_thresh.txt'.format(i=model_path[12:-4]), [best_thresh])\n",
    "    else:\n",
    "        with open('predictions/'+model_path[12:-4]+'_on_original', \"wb\") as fp:\n",
    "            pickle.dump(np.array(prob), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_best_thresh(y_test, y_preds):\n",
    "    best_thresh = 0\n",
    "    best = 0\n",
    "    tprs, fprs, threshes = get_threshes(y_test, y_preds)\n",
    "        \n",
    "    for i in range(len(threshes)):\n",
    "        score = f1_score(y_test, np.where(y_preds >= threshes[i], 1, 0), average='binary')\n",
    "        if (score > best):\n",
    "            best = score\n",
    "            best_thresh = threshes[i]\n",
    "                \n",
    "    return best_thresh\n",
    "\n",
    "def get_threshes(y_test, preds):\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(y_test, preds, drop_intermediate=False)\n",
    "        \n",
    "    return tpr, fpr, threshold\n",
    "\n",
    "def get_tpr(y_test, preds, thresh):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, np.where(preds >= thresh, 1, 0)).ravel()\n",
    "    \n",
    "    return tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_new.csv')\n",
    "data_path = '../../../mnt/usb/kuopc/ADNI_B1/MPR__GradWarp__B1_Correction_crop/'\n",
    "\n",
    "df = df.loc[df['Group'] != 'MCI']\n",
    "# df = df.loc[df['Age'] <= 75]\n",
    "\n",
    "\n",
    "class_0 = df['Group'].value_counts()[0]\n",
    "class_1 = df['Group'].value_counts()[1]\n",
    "\n",
    "total = class_0 + class_1\n",
    "\n",
    "weight_for_0 = (1 / class_0) * (total / 2.0)\n",
    "weight_for_1 = (1 / class_1) * (total / 2.0)\n",
    "\n",
    "weights = torch.tensor([weight_for_0, weight_for_1], dtype=torch.float32)\n",
    "\n",
    "print(weights)\n",
    "print(type(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-spotlight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_shape = (1, 96, 96, 96)\n",
    "batch_size = 16\n",
    "\n",
    "np.random.seed(2021)\n",
    "torch.manual_seed(2021)\n",
    "\n",
    "epochs = 80\n",
    "\n",
    "model_path = 'checkpoints/3D_CNN_AD_CN_Adv.pth'\n",
    "\n",
    "model = resnet3d_model(18, adv=True)\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     if not ('fc' in name):\n",
    "#         param.requires_grad = False\n",
    "\n",
    "# model_path = 'checkpoints/3D_CNN_AD_CN_proposed_task_transfer_race.pth'\n",
    "\n",
    "optimizer = Adam(model.parameters(),lr=1e-5, weight_decay=1e-6) \n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.1) \n",
    "\n",
    "task = 'disease'\n",
    "algo = 'Adv'\n",
    "\n",
    "train_step(model, df, data_path, model_path, epochs, -2, task, algo)\n",
    "eval_step(model, df, data_path, model_path, True, -2, task)     \n",
    "\n",
    "eval_step(model, df, data_path, model_path, False, -2, task)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(file_path):\n",
    "    data = nib.load(file_path)\n",
    "    data = np.array(data.dataobj)\n",
    "    return data\n",
    "\n",
    "def normalize(arr):\n",
    "    arr_min = np.min(arr)\n",
    "    arr_max = np.max(arr)\n",
    "    return (arr - arr_min) / (arr_max - arr_min)\n",
    "\n",
    "with torch.no_grad():\n",
    "    def compute_aug_predictions(model, model_path, df, data_path):\n",
    "        seed = 2021\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        y_preds = []\n",
    "\n",
    "        loop = tqdm(enumerate(df['Filename']), total =len(df['Filename']))\n",
    "        for i, file in loop:\n",
    "\n",
    "            file_path = data_path + file\n",
    "            image = load_img(file_path)\n",
    "\n",
    "            aug_inputs = []\n",
    "            for _ in range(3):\n",
    "\n",
    "                try:\n",
    "                    aug_img = shear(image, 6)\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "                except:\n",
    "                    aug_img = image\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "\n",
    "                try:\n",
    "                    aug_img = rotation(image, 10)\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "                except:\n",
    "                    aug_img = image\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "\n",
    "                try:\n",
    "                    aug_img = fish(image, 0.4)\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "                except:\n",
    "                    aug_img = image\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "\n",
    "                try:\n",
    "                    aug_img = scale(image, 0.8)\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "                except:\n",
    "                    aug_img = image\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "\n",
    "                del aug_img\n",
    "                gc.collect()\n",
    "\n",
    "            aug_inputs = torch.unsqueeze(torch.from_numpy(np.array(aug_inputs)), 1).to(device)\n",
    "\n",
    "            temp_predict = model(aug_inputs)\n",
    "\n",
    "            y_preds.append(torch.mean(temp_predict))\n",
    "\n",
    "            del aug_inputs, image, temp_predict\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            print(i)\n",
    "\n",
    "\n",
    "        with open('predictions/'+model_path[12:-4]+'_on_aug', \"wb\") as fp:\n",
    "            pickle.dump(np.array(y_preds), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-improvement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    img_shape = (1, 96, 96, 96)\n",
    "    batch_size = 1\n",
    "\n",
    "    np.random.seed(2021)\n",
    "    torch.manual_seed(2021)\n",
    "\n",
    "    df = pd.read_csv('data_new.csv')\n",
    "    data_path = '../../../mnt/usb/kuopc/ADNI_B1/MPR__GradWarp__B1_Correction_crop/'\n",
    "\n",
    "    df = df.loc[df['Group'] != 'MCI']\n",
    "    df = df.loc[df['Split'] == 'test']\n",
    "\n",
    "    model_path = 'checkpoints/3D_CNN_AD_CN_Adv.pth'\n",
    "\n",
    "    model = resnet3d_model(18)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    compute_aug_predictions(model, model_path, df, data_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe5a9d7ed15783e8a7a59b50df3e0c454a9bbc278a1b7ec2a6ccdea2d04cfc00"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
